{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#PREDICTIVE TEXT MODEL\n",
        "\n",
        "Step 1: Make a folder \"ACM_Project\" in your Google Drive. ( such that its path is \"/content/drive/MyDrive/ACM_Project\" )\n",
        "\n",
        "Step 2: Upload the following files to this folder:\n",
        "\n",
        " ->  nextword1.h5\n",
        "\n",
        " ->  tokenizer1.pkl\n",
        "\n",
        " ->  Taylor Swift.txt (this is optional, it contains the data that the model has been trained upon. You can refer to it for testing.)\n",
        "\n",
        "Step 3: Mount you Google Drive in Google Colab.\n",
        "\n",
        "Then run this code. \n",
        "\n",
        "NOTE: Type \"stop the script\" to end the program.\n"
      ],
      "metadata": {
        "id": "BL6dcqkxdxD8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHQQxVgJdD7l"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "# Load the model and tokenizer\n",
        "\n",
        "model = load_model('/content/drive/MyDrive/ACM_Project/nextword1.h5')\n",
        "tokenizer = pickle.load(open('/content/drive/MyDrive/ACM_Project/tokenizer1.pkl', 'rb'))\n",
        "\n",
        "def Predict_Next_Words(model, tokenizer, text):\n",
        "    \"\"\"\n",
        "        In this function we are using the tokenizer and models trained\n",
        "        and we are creating the sequence of the text entered and then\n",
        "        using our model to predict and return the the predicted word.\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    \n",
        "    \n",
        "    sequence = tokenizer.texts_to_sequences([text])\n",
        "    sequence = np.array(sequence)\n",
        "    \n",
        "    \n",
        "    #  preds = model.predict_classes(sequence)\n",
        "    predict_x=model.predict(sequence) \n",
        "    preds=np.argmax(predict_x)\n",
        "    \n",
        "    # print(preds)\n",
        "    predicted_word = \"\"\n",
        "    \n",
        "    for key, value in tokenizer.word_index.items():\n",
        "        if value == preds:\n",
        "            predicted_word = key\n",
        "            break\n",
        "    \n",
        "    print(predicted_word)\n",
        "    return predicted_word"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "while(True):\n",
        "\n",
        "    text = input(\"Enter your line: \")\n",
        "    \n",
        "    if text == \"stop the script\":\n",
        "        print(\"Ending The Program.....\")\n",
        "        break\n",
        "    \n",
        "    else:\n",
        "        try:\n",
        "            text = text.split(\" \")\n",
        "            text = text[-5:]\n",
        "            Predict_Next_Words(model, tokenizer, text)\n",
        "            \n",
        "        except:\n",
        "            continue"
      ],
      "metadata": {
        "id": "EzBD7o0-dMW2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c651736-19c4-405d-9149-ef7888a15090"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your line: I know Iâ€™m probably better off all\n",
            "1/1 [==============================] - 1s 997ms/step\n",
            "alone\n",
            "Enter your line: And I know why we had to say\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "goodbye\n",
            "Enter your line: He got that boyish look that I like in a\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "man\n"
          ]
        }
      ]
    }
  ]
}